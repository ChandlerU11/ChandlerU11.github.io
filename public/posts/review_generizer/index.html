<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Using Unsupervised ML to &#39;Typicalize&#39; Product Reviews | Chandler Underwood</title>
<meta name="keywords" content="">
<meta name="description" content="Using NLP and unsupervised machine learning techniques, I create a model that can select the most typical samples to represent a set of reviews containing a keyword.">
<meta name="author" content="Chandler Underwood">
<link rel="canonical" href="https://chandleru11.github.io/posts/review_generizer/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://chandleru11.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://chandleru11.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://chandleru11.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://chandleru11.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://chandleru11.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://chandleru11.github.io/posts/review_generizer/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Using Unsupervised ML to &#39;Typicalize&#39; Product Reviews" />
<meta property="og:description" content="Using NLP and unsupervised machine learning techniques, I create a model that can select the most typical samples to represent a set of reviews containing a keyword." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chandleru11.github.io/posts/review_generizer/" /><meta property="og:image" content="https://chandleru11.github.io/images/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-07-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-07-10T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://chandleru11.github.io/images/papermod-cover.png"/>

<meta name="twitter:title" content="Using Unsupervised ML to &#39;Typicalize&#39; Product Reviews"/>
<meta name="twitter:description" content="Using NLP and unsupervised machine learning techniques, I create a model that can select the most typical samples to represent a set of reviews containing a keyword."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://chandleru11.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Using Unsupervised ML to 'Typicalize' Product Reviews",
      "item": "https://chandleru11.github.io/posts/review_generizer/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Using Unsupervised ML to 'Typicalize' Product Reviews",
  "name": "Using Unsupervised ML to \u0027Typicalize\u0027 Product Reviews",
  "description": "Using NLP and unsupervised machine learning techniques, I create a model that can select the most typical samples to represent a set of reviews containing a keyword.",
  "keywords": [
    
  ],
  "articleBody": "\r\u003c!DOCTYPE html\u003e Motivation In my last post where I scraped reviews for Crocs Clogs, I mentioned that I often find myself wishing for a succinct summary of the reviews for a product. Let’s flesh that out a bit more. What I mean when I say “succinct summary” is that I want a quick understanding of a specific aspect for a given product. For example, I know that crocs come in amazing colors already. I can see that in the photos. But, how do they fit? What about their comfort? I find myself often most concerned with a specific aspect of a product such as those. I want to know what people are typically saying about fit and comfort. Many retailers offer a search bar for reviews, so you can filter reviews on a keyword. BUT, searching for “fit” across all crocs reviews would return a ton of samples, and how can we know which ones are representative of the general sentiment people have in regards to fit? What if we could give consumers a snapshot of the reviews containing a word or phrase they search for? Could we show them a small set of reviews that best represent all the reviews that mention the word “fit”, for example? I think we can!\nHow to Make it Happen Did someone say centroid-based clustering??? Because they would be correct. For this project we will be using the most popular centroid-based clustering algorithm, k-means.\nAccording to Wikipedia - k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.\nIn other words, k-means searches for the best representation of each cluster (the center) and assigns samples to a cluster based on their distance from each cluster center. So, we can say that a cluster’s center is an approximation of all the cluster’s members. Following this line of thinking, if we fit a k-means model to some data and only ask it to find 1 cluster, the calculated cluster center will act as a prototype for all the data that was passed to the model. To find the most representative subset of reviews for a particular keyword, we can filter the reviews based on the keyword, find a cluster center for the remaining samples, and get the X closest samples to the center. The closest samples to the center will be the most representative of the population. If this isn’t clear, check out the GIF below and imagine we’re only trying to make one cluster. Think about how the cluster center / centroid would move in that scenario.\nCredit - Sebastian Charmot, https://towardsdatascience.com/clear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410\nTools Needed Of course we will need Pandas to make for easy data manipulation and usage. We also will need to clean up our text data, so we’ll use NLTK. Finally, we need a way to vectorize the text and fit a k-means model to it, so we’ll use Scikit-Learn for that part.\nimport pandas as pd from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.cluster import KMeans import nltk from nltk.corpus import stopwords from nltk.stem import PorterStemmer import re import string Clean Review Data It’s usually very important that we stem, remove punctuation, convert to lowercase, and remove stopwords from the text we’re fitting a model on. We don’t want “Oranges” and “orange” to be treated as different words, nor do we need words like “the” and “to”, for example.\ndef clean_text(text): # Remove punctuation text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text) # Convert to lowercase text = text.lower() # Remove stopwords nltk.download('stopwords', quiet=True) stop_words = set(stopwords.words('english')) tokens = nltk.word_tokenize(text) tokens = [word for word in tokens if word.lower() not in stop_words] # Stemming stemmer = PorterStemmer() tokens = [stemmer.stem(word) for word in tokens] # Join the tokens back into a single string cleaned_text = ' '.join(tokens) return cleaned_text df = pd.read_csv('data\\croc_reviews.csv') df['clean_review'] = [clean_text(text_to_clean) for text_to_clean in df['review']] df review date rating clean_review 0 !!!!!! E X C E L L E N T!!!!!!!!!! April 7, 2022 5.0 e x c e l l e n 1 \"They're crocs; people know what crocs are.\" April 3, 2021 5.0 theyr croc peopl know croc 2 - Quick delivery and the product arrived when ... March 19, 2023 5.0 quick deliveri product arriv compani said woul... 3 ...amazing \"new\" color!! who knew?? love - lov... July 17, 2022 5.0 amaz new color knew love love love 4 0 complaints from me; this is the 8th pair of ... June 4, 2021 5.0 0 complaint 8th pair croc ive bought like two ... ... ... ... ... ... 9233 I will definitely be buying again in many colo... August 25, 2021 4.0 definit buy mani color reason 45 materi feel t... 9234 I wish I would have bought crocs a long time ago. April 8, 2021 5.0 wish would bought croc long time ago 9235 wonderful. Gorgeous blue; prettier in person! April 27, 2022 5.0 wonder gorgeou blue prettier person 9236 Wonerful. Very comfy, and there are no blister... April 8, 2021 5.0 woner comfi blister feet unlik brand one 9237 Work from home - high arch need good support a... May 22, 2023 5.0 work home high arch need good support comfort ... 9238 rows × 4 columns\nSome Notes on Vectorization Methods Since it’s been decided we’re using k-means for this project, we’re going to try out two vectorization methods and compare their performance. For each of our vectorization methods, we’ll also compute an example of their output using the two phrases “going to the store to buy bananas” and “we buy bananas” here. The vectorizers are the following:\nTF-IDF - term frequency-inverse document frequency helps by giving us an understanding of how important a word is within a document relative to an entire corpus. It is calculated by multiplying a word’s term frequency (TF) with its inverse document frequency (IDF). TF = # of times word appears in a document / total # of terms in document IDF = log(# of documents in corpus / # of documents in corpus that contain term) TF-IDF = Tf X IDF Sample bananas buy going store the to we “going to the store to buy bananas” 0.25 0.25 0.35 0.35 0.35 0.71 0.0 “we buy bananas” 0.50 0.50 0.0 0.0 0.0 0.0 0.70 CountVectorizer - Count vectorization converts a collection of text documents into a matrix of token counts. Every word in the corpus gets its own column, so every document is converted into a vector containing the frequency of its words. Sample bananas buy going store the to we “going to the store to buy bananas” 1 1 1 1 1 2 0 “we buy bananas” 1 1 0 0 0 0 1 Finding Typical Reviews The workflow for finding the most typical reviews will be:\nFilter reviews on a keyword and rating (either positive or negative) Vectorize the reviews with TF-IDF or CountVectorizer Fit a single k-means cluster Calculate the distance of each sample to the center of the cluster and sort def get_tfidf(text): vectorizer = TfidfVectorizer() # Fit and transform review data X = vectorizer.fit_transform(text) return X def get_countvect(text): vectorizer = CountVectorizer() # Fit and transform review data X = vectorizer.fit_transform(text) return X def kmeans_distance(df, vect): # Vectorize reviews using TF-IDF if vect == 'tfidf': X = get_tfidf(df['clean_review']) # Vectorize reviews using CountVectorizer elif vect == 'count': X = get_countvect(df['clean_review']) else: print(\"Provide a vectorization method\") # Fit one cluster on the data. kmeans = KMeans(n_clusters=1, random_state=0, n_init=100).fit(X) # Compute the distance for each sample to the center of the cluster distances = kmeans.transform(X)**2 return distances def find_most_typical(df, word, rating, vect, asc = True): # Let's consider anything 4 stars and up a positive review if rating == 'positive': df = df[df['rating'] \u003e= 4] else: df = df[df['rating'] \u003c 4] # Clean word so it matches root word in cleaned reviews filter_word = ' ' + clean_text(word) + ' ' #Filter using clean word df = df[df['clean_review'].str.contains(filter_word, regex = True)] # Retrieve review distance to center of kmeans cluster df['distance_to_center'] = kmeans_distance(df, vect) print(\"There are\", len(df), rating, \"reviews that mention:\", word) if asc == True: print(\"The most typical reviews are:\") else: print(\"The most atypical reviews are:\") for each in df.sort_values(by = 'distance_to_center', ascending = asc)['review'].tolist()[:3]: print('# ', each) Pseudo-evaluation We don’t really have a way to evaluate this model, so we’re going to have to use some intuition! Firstly, let’s look at what the 3 most typical positive reviews that mention “crocs” using TF-IDF and CountVectorizer would say.\nfind_most_typical(df, 'crocs', 'positive', 'tfidf') There are 2268 positive reviews that mention: crocs Most typical reviews are: # I love to wear these crocs because they are so comfortable. # I love wearing my crocs. They are so comfortable. # I love my pair of Crocs. They are so comfortable! find_most_typical(df, 'crocs', 'positive', 'count') There are 2268 positive reviews that mention: crocs Most typical reviews are: # I own a few pairs of crocs and love them all. # I love my Crocs; they are so comfortable. # I love Crocs; they are so comfortable! To make sure we’re on the right track, what do the most atypical positive reviews for crocs say? We can find the samples that are farthest from the center by sorting their distance greatest to smallest.\nfind_most_typical(df, 'crocs', 'positive', 'tfidf', asc = False) There are 2268 positive reviews that mention: crocs Most atypical reviews are: # Lids adore their Crocs! Fun with swapping charms and accessoryizing. # Purr Nickis Impact Crocs. Ima need you to give my girl a ha check!!!! # You can turn any none-croc person into a croc lover. find_most_typical(df, 'crocs', 'positive', 'count', asc = False) There are 2268 positive reviews that mention: crocs Most atypical reviews are: # Do you really need one more Croc review to convince you to buy these shoes? Never in a kabillion years did I think I'd ever buy a pair of Crocs. Nope, not my style, not my vibe, and not me, ever. But the husband had plantar fasciitis in one of his feet, and the pain was incredible. There are several options for shoes, but we're on a budget, and I kept reading about Crocs as a good starting point. So I ordered him some Crocs in the olive green. Then I thought, \"My husband is a big baby. I should order myself a pair, wear them around for a day, and rave about them so he'll immediately start wearing his own pair of Crocs and start healing his feet.\" The thing is, I was totally gobsmacked. At first the prickly nubs in the footbed were a bit distracting, but as I started walking around in them, they became less noticeable, and within the first twenty minutes or so, my feet started to feel energized and soothed. I went outside and swept the deck and did some chicken chores, and I was just in heaven. My legs felt supported and I had this incredible feeling of a whole body support system, starting with the acupressure from the footbed nubs and the lightweight shoe material and the fabulous cushioning. These shoes haven't had enough time to mold to my feet, and I'm already blissed out wearing them. I got mine in the olive green, too. They're earthy and surprisingly cute. My husband hasn't worn a clog in his entire life and walked off wearing them for the first time as if little elves were sitting inside his shoes and if he stepped down too hard, they'd get squished and died. A few minutes later, I saw him disappear down the hill at the back of our property. He can't walk when he gets home, his feet are in that much pain. # I was looking for something to wear at night while I was on the AIDS/Lifecycle. It's a 545 mile bicycle ride from San Francisco to Los Angeles where we raise money for services to HIV+ patients. The ride involves six nights of camping. It's a huge event and the evenings involve a lot of walking. We are allowed 70lbs of gear, but we have to haul our gear to our tent site every night, so traveling light is important. I wanted one pair of shoes for the week that I could put on after riding my bike all day and they would be comfortable enough to wear all week. I wanted one pair of shoes that wasn't going to get icky if the grass was wet at the campsite in the morning. I wanted one pair of shoes that kept my feet warm while I was walking around the campsite in the evening. These shoes totally fit the bill. After beating up my feet all day in cleats on the bike, they were a welcome respite. They allowed air to flow, but my feet never got cold at night. Dirt just wiped off. If I got some gravel in them, it kicked right back out. These shoes were so comfortable I found myself next to the gear trucks digging through my bag to find them and put them on. I know a lot of athletes use Crocs after their activity to kick around in, and these shoes are the shiznit! # These are my first Crocs, and lavender seems to run *almost* a size small. I would say the size 8 Crocs in lavender fits closer to 7 than size 8 street shoes. For reference, I wear size 7 in street shoes (Vans, Converse, Franco Sarto boots, Timberland Kinsley boots), size 38 European shoes (Veja), size 8 running shoes (Mizuno Wave Riders), size 8 Vasque Mesa Trek hiking boots. If you can, try them on. When I measured my feet and checked the Crocs size chart, it said I was a size 10, which would have been way too big. Size 8 lavender fit me roomy but comfortable, whether I'm barefoot or wearing thick, fluffy socks, with or without the Crocs shoe strap. They're super comfy! Those are definitely a bit weird! But, it looks like we’ve built something that works. Very cool.\nLooking at More Keywords and Ratings Let’s see what people have to say about the comfort and fit of crocs that is positive using both our vectorization methods.\nfind_most_typical(df, 'comfort', 'positive', 'tfidf') There are 1847 positive reviews that mention: comfort Most typical reviews are: # The crocs are very comfortable. I love them. # The crocs are comfortable, and I love them. # I love the color and comfort of these crocs! find_most_typical(df, 'comfort', 'positive', 'count') There are 1847 positive reviews that mention: comfort Most typical reviews are: # The crocs are very comfortable. I love them. # The crocs are comfortable, and I love them. # I love them; they are so comfortable to wear. find_most_typical(df, 'fit', 'positive', 'tfidf') There are 834 positive reviews that mention: fit Most typical reviews are: # Love the color and fit just as comfortably as my other crocs. # I love these. They are a perfect fit and very comfortable. I love the color as well. # Very comfortable and great fit. I love them. find_most_typical(df, 'fit', 'positive', 'count') There are 834 positive reviews that mention: fit Most typical reviews are: # I love them, and they fit great. # They are a great fit and are comfortable. # These are so comfortable, and it fits perfect! What do they say about those aspects that is negative?\nfind_most_typical(df, 'comfort', 'negative', 'tfidf') There are 68 negative reviews that mention: comfort Most typical reviews are: # I loved Crocs until my shoe size went to 8.5. Now the 9 is too big \u0026 the 8 is too small. I can't really comfortably wear either pair. # I love crocs; they're my favorite. However, for some reason, their sizing has gotten inaccurate. I have an old pair of size 8 women's \u0026 it's a perfect comfortable fit, and this time I ordered the same size 8 women's, and it's a little too snug for my comfort, and my toes have less room than usual. # I love how comfortable this shoe is. However, I wish they had half sizes because I am a 10 1/2 in women and I knew the regular 10 was going to be small, so I got an 11. I didn't like how big it made my feet look. I hope they change their sizing and add half sizes too. find_most_typical(df, 'comfort', 'negative', 'count') There are 68 negative reviews that mention: comfort Most typical reviews are: # I like how comfortable they are, but they are not true to size because they are too small. # The sole isn't comfortable for my feet. Standing long in the pair can be painful. # I bought these for my daughter. She said these are not comfortable like true clogs. find_most_typical(df, 'fit', 'negative', 'tfidf') There are 169 negative reviews that mention: fit Most typical reviews are: # I have over 20 pairs of crocs, and lately, the last 5 pairs I've purchased have all fit differently. I'm usually a men's 8 \u0026 recently bought a red pair of the classic clog. They were entirely too big, which made no sense because I have pink ones the same size that fit perfectly. I purchased a purple pair \u0026 decided to size down \u0026 get a men's 7 \u0026 they were way too small (which also made no sense because I have blue crocs the same size that were a more snug fit). My suggestion is to either make half sizes, or stop with this whole \"Roomy Fit\" thing that you all are doing. There is zero reason why each pair of crocs should have a different fit. I'll never order crocs online again. I highly recommend just going to the store to make your purchase. The return process is also very strenuous because Crocs does not offer exchanges. So now I have to send them back to the store via UPS, wait for my return to be processed, then wait until I can make my way to a crocs store because the closest store in my area is 36.6 miles away. Ridiculous. # Well, the crocs do not fit my granddaughter. One is actually a different size than the other. She received another pair of Crocs from her dad, and even though the pair he got her are size 9, and the pair I got her are size 9, the pair he bought her fits and the ones I got her do not. One pair was made in China and one pair was made in Vietnam. # I have had several pairs of crocs in the past, different styles and colors. Direct from the company. I have been disappointed in the consistency of the sizing. I had a size 10 in the classic style and wanted another pair in a different color. When they arrived, the fit was at least a size larger and wider than my original pair. Then I exchanged for a size 9. This fit better, but now the left shoe is smaller than the right. Not happy. find_most_typical(df, 'fit', 'negative', 'count') There are 169 negative reviews that mention: fit Most typical reviews are: # I ordered size 11 because they r too big. I thought they fit to size. # This pair fits a little short. # One pair of my crocs was a perfect fit, but the other fit was weird. Conclusion Well that was fun! After going through and reading the model outputs, it seems that CountVectorizer works the best for solving this problem. Which makes sense considering we are most concerned with finding the most “typical” reviews, and CountVectorizer focuses solely on term frequency to represent documents. Using CountVectorizer seems partial to the selection of shorter reviews, which I would consider an advantage in this space. Quick and succinct is the name of the game here. I really like this idea and may deploy a model based on this concept in the future…\n",
  "wordCount" : "3350",
  "inLanguage": "en",
  "datePublished": "2024-07-10T00:00:00Z",
  "dateModified": "2024-07-10T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Chandler Underwood"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chandleru11.github.io/posts/review_generizer/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chandler Underwood",
    "logo": {
      "@type": "ImageObject",
      "url": "https://chandleru11.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://chandleru11.github.io/" accesskey="h" title="Chandler Underwood (Alt + H)">Chandler Underwood</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://chandleru11.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://chandleru11.github.io/archives" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://chandleru11.github.io/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://chandleru11.github.io/publications" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://chandleru11.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://chandleru11.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Using Unsupervised ML to &#39;Typicalize&#39; Product Reviews
    </h1>
    <div class="post-description">
      Using NLP and unsupervised machine learning techniques, I create a model that can select the most typical samples to represent a set of reviews containing a keyword.
    </div>
    <div class="post-meta"><span title='2024-07-10 00:00:00 +0000 UTC'>July 10, 2024</span>&nbsp;·&nbsp;16 min&nbsp;·&nbsp;Chandler Underwood

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#motivation" aria-label="Motivation">Motivation</a></li>
                <li>
                    <a href="#how-to-make-it-happen" aria-label="How to Make it Happen">How to Make it Happen</a></li>
                <li>
                    <a href="#tools-needed" aria-label="Tools Needed">Tools Needed</a></li>
                <li>
                    <a href="#clean-review-data" aria-label="Clean Review Data">Clean Review Data</a></li>
                <li>
                    <a href="#some-notes-on-vectorization-methods" aria-label="Some Notes on Vectorization Methods">Some Notes on Vectorization Methods</a></li>
                <li>
                    <a href="#finding-typical-reviews" aria-label="Finding Typical Reviews">Finding Typical Reviews</a></li>
                <li>
                    <a href="#pseudo-evaluation" aria-label="Pseudo-evaluation">Pseudo-evaluation</a><ul>
                        
                <li>
                    <a href="#looking-at-more-keywords-and-ratings" aria-label="Looking at More Keywords and Ratings">Looking at More Keywords and Ratings</a></li></ul>
                </li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content">

<!DOCTYPE html>
<html>
<head>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0NTZD30YVX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0NTZD30YVX');
</script>
</head>
</html>

<h1 id="motivation">Motivation<a hidden class="anchor" aria-hidden="true" href="#motivation">#</a></h1>
<p>In my <a href="https://chandleru11.github.io/posts/review_scrape/">last post</a> where I scraped reviews for Crocs Clogs, I mentioned that I often find myself wishing for a succinct summary of the reviews for a product. Let&rsquo;s flesh that out a bit more. What I mean when I say &ldquo;succinct summary&rdquo; is that I want a quick understanding of a specific aspect for a given product. For example, I know that crocs come in amazing colors already. I can see that in the photos. But, how do they fit? What about their comfort? I find myself often most concerned with a specific aspect of a product such as those. I want to know what people are typically saying about fit and comfort. Many retailers offer a search bar for reviews, so you can filter reviews on a keyword. BUT, searching for &ldquo;fit&rdquo; across all crocs reviews would return a ton of samples, and how can we know which ones are representative of the general sentiment people have in regards to fit? What if we could give consumers a snapshot of the reviews containing a word or phrase they search for? Could we show them a small set of reviews that best represent all the reviews that mention the word &ldquo;fit&rdquo;, for example? I think we can!</p>
<h1 id="how-to-make-it-happen">How to Make it Happen<a hidden class="anchor" aria-hidden="true" href="#how-to-make-it-happen">#</a></h1>
<p>Did someone say centroid-based clustering??? Because they would be correct. For this project we will be using the most popular centroid-based clustering algorithm, <em>k</em>-means.</p>
<p>According to Wikipedia - <em>k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster.</em></p>
<p>In other words, <em>k</em>-means searches for the best representation of each cluster (the center) and assigns samples to a cluster based on their distance from each cluster center. So, we can say that a cluster&rsquo;s center is an approximation of all the cluster&rsquo;s members. Following this line of thinking, if we fit a <em>k</em>-means model to some data and only ask it to find 1 cluster, the calculated cluster center will act as a prototype for all the data that was passed to the model. To find the most representative subset of reviews for a particular keyword, we can filter the reviews based on the keyword, find a cluster center for the remaining samples, and get the X closest samples to the center. The closest samples to the center will be the most representative of the population. If this isn&rsquo;t clear, check out the GIF below and imagine we&rsquo;re only trying to make one cluster. Think about how the cluster center / centroid would move in that scenario.</p>
<p><img loading="lazy" src="/keans.gif" alt="Scenario 1: Across columns"  />

Credit - Sebastian Charmot, <a href="https://towardsdatascience.com/clear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410">https://towardsdatascience.com/clear-and-visual-explanation-of-the-k-means-algorithm-applied-to-image-compression-b7fdc547e410</a></p>
<h1 id="tools-needed">Tools Needed<a hidden class="anchor" aria-hidden="true" href="#tools-needed">#</a></h1>
<p>Of course we will need Pandas to make for easy data manipulation and usage. We also will need to clean up our text data, so we&rsquo;ll use NLTK. Finally, we need a way to vectorize the text and fit a <em>k</em>-means model to it, so we&rsquo;ll use Scikit-Learn for that part.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">nltk</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">PorterStemmer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">re</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">string</span>
</span></span></code></pre></div><h1 id="clean-review-data">Clean Review Data<a hidden class="anchor" aria-hidden="true" href="#clean-review-data">#</a></h1>
<p>It&rsquo;s usually very important that we stem, remove punctuation, convert to lowercase, and remove stopwords from the text we&rsquo;re fitting a model on. We don&rsquo;t want &ldquo;Oranges&rdquo; and &ldquo;orange&rdquo; to be treated as different words, nor do we need words like &ldquo;the&rdquo; and &ldquo;to&rdquo;, for example.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">clean_text</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Remove punctuation</span>
</span></span><span class="line"><span class="cl">    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;[</span><span class="si">{</span><span class="n">re</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span><span class="si">}</span><span class="s2">]&#34;</span><span class="p">,</span> <span class="s2">&#34;&#34;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Convert to lowercase</span>
</span></span><span class="line"><span class="cl">    <span class="n">text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Remove stopwords</span>
</span></span><span class="line"><span class="cl">    <span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">,</span> <span class="n">quiet</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">stop_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">word</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">word</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Stemming</span>
</span></span><span class="line"><span class="cl">    <span class="n">stemmer</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Join the tokens back into a single string</span>
</span></span><span class="line"><span class="cl">    <span class="n">cleaned_text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">cleaned_text</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data\croc_reviews.csv&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_review&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">clean_text</span><span class="p">(</span><span class="n">text_to_clean</span><span class="p">)</span> <span class="k">for</span> <span class="n">text_to_clean</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span>
</span></span></code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>date</th>
      <th>rating</th>
      <th>clean_review</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>!!!!!! E X C E L L E N T!!!!!!!!!!</td>
      <td>April 7, 2022</td>
      <td>5.0</td>
      <td>e x c e l l e n</td>
    </tr>
    <tr>
      <th>1</th>
      <td>"They're crocs; people know what crocs are."</td>
      <td>April 3, 2021</td>
      <td>5.0</td>
      <td>theyr croc peopl know croc</td>
    </tr>
    <tr>
      <th>2</th>
      <td>- Quick delivery and the product arrived when ...</td>
      <td>March 19, 2023</td>
      <td>5.0</td>
      <td>quick deliveri product arriv compani said woul...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>...amazing "new" color!! who knew?? love - lov...</td>
      <td>July 17, 2022</td>
      <td>5.0</td>
      <td>amaz new color knew love love love</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0 complaints from me; this is the 8th pair of ...</td>
      <td>June 4, 2021</td>
      <td>5.0</td>
      <td>0 complaint 8th pair croc ive bought like two ...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>9233</th>
      <td>I will definitely be buying again in many colo...</td>
      <td>August 25, 2021</td>
      <td>4.0</td>
      <td>definit buy mani color reason 45 materi feel t...</td>
    </tr>
    <tr>
      <th>9234</th>
      <td>I wish I would have bought crocs a long time ago.</td>
      <td>April 8, 2021</td>
      <td>5.0</td>
      <td>wish would bought croc long time ago</td>
    </tr>
    <tr>
      <th>9235</th>
      <td>wonderful. Gorgeous blue; prettier in person!</td>
      <td>April 27, 2022</td>
      <td>5.0</td>
      <td>wonder gorgeou blue prettier person</td>
    </tr>
    <tr>
      <th>9236</th>
      <td>Wonerful. Very comfy, and there are no blister...</td>
      <td>April 8, 2021</td>
      <td>5.0</td>
      <td>woner comfi blister feet unlik brand one</td>
    </tr>
    <tr>
      <th>9237</th>
      <td>Work from home - high arch need good support a...</td>
      <td>May 22, 2023</td>
      <td>5.0</td>
      <td>work home high arch need good support comfort ...</td>
    </tr>
  </tbody>
</table>
<p>9238 rows × 4 columns</p>
</div>
<h1 id="some-notes-on-vectorization-methods">Some Notes on Vectorization Methods<a hidden class="anchor" aria-hidden="true" href="#some-notes-on-vectorization-methods">#</a></h1>
<p>Since it&rsquo;s been decided we&rsquo;re using <em>k</em>-means for this project, we&rsquo;re going to try out two vectorization methods and compare their performance. For each of our vectorization methods, we&rsquo;ll also compute an example of their output using the two phrases &ldquo;going to the store to buy bananas&rdquo; and &ldquo;we buy bananas&rdquo; here. The vectorizers are the following:</p>
<ul>
<li><strong>TF-IDF</strong> - term frequency-inverse document frequency helps by giving us an understanding of how important a word is within a document relative to an entire corpus. It is calculated by multiplying a word&rsquo;s term frequency (TF) with its inverse document frequency (IDF).</li>
</ul>
<pre tabindex="0"><code>TF = # of times word appears in a document / total # of terms in document
IDF = log(# of documents in corpus / # of documents in corpus that contain term)
TF-IDF = Tf X IDF
</code></pre><table>
  <thead>
      <tr>
          <th><strong>Sample</strong></th>
          <th>bananas</th>
          <th>buy</th>
          <th>going</th>
          <th>store</th>
          <th>the</th>
          <th>to</th>
          <th>we</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>&ldquo;going to the store to buy bananas&rdquo;</td>
          <td>0.25</td>
          <td>0.25</td>
          <td>0.35</td>
          <td>0.35</td>
          <td>0.35</td>
          <td>0.71</td>
          <td>0.0</td>
      </tr>
      <tr>
          <td>&ldquo;we buy bananas&rdquo;</td>
          <td>0.50</td>
          <td>0.50</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>0.0</td>
          <td>0.70</td>
      </tr>
  </tbody>
</table>
<ul>
<li><strong>CountVectorizer</strong> - Count vectorization converts a collection of text documents into a matrix of token counts. Every word in the corpus gets its own column, so every document is converted into a vector containing the frequency of its words.</li>
</ul>
<table>
  <thead>
      <tr>
          <th><strong>Sample</strong></th>
          <th>bananas</th>
          <th>buy</th>
          <th>going</th>
          <th>store</th>
          <th>the</th>
          <th>to</th>
          <th>we</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>&ldquo;going to the store to buy bananas&rdquo;</td>
          <td>1</td>
          <td>1</td>
          <td>1</td>
          <td>1</td>
          <td>1</td>
          <td>2</td>
          <td>0</td>
      </tr>
      <tr>
          <td>&ldquo;we buy bananas&rdquo;</td>
          <td>1</td>
          <td>1</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>0</td>
          <td>1</td>
      </tr>
  </tbody>
</table>
<h1 id="finding-typical-reviews">Finding Typical Reviews<a hidden class="anchor" aria-hidden="true" href="#finding-typical-reviews">#</a></h1>
<p>The workflow for finding the most typical reviews will be:</p>
<ol>
<li>Filter reviews on a keyword and rating (either positive or negative)</li>
<li>Vectorize the reviews with TF-IDF or CountVectorizer</li>
<li>Fit a single <em>k</em>-means cluster</li>
<li>Calculate the distance of each sample to the center of the cluster and sort</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_tfidf</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Fit and transform review data</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">X</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_countvect</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Fit and transform review data</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">X</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">kmeans_distance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">vect</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Vectorize reviews using TF-IDF </span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">vect</span> <span class="o">==</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">:</span>   
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">get_tfidf</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_review&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Vectorize reviews using CountVectorizer</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">vect</span> <span class="o">==</span> <span class="s1">&#39;count&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">get_countvect</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_review&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Provide a vectorization method&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Fit one cluster on the data.</span>
</span></span><span class="line"><span class="cl">    <span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Compute the distance for each sample to the center of the cluster</span>
</span></span><span class="line"><span class="cl">    <span class="n">distances</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">distances</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">rating</span><span class="p">,</span> <span class="n">vect</span><span class="p">,</span> <span class="n">asc</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Let&#39;s consider anything 4 stars and up a positive review</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">rating</span> <span class="o">==</span> <span class="s1">&#39;positive&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;rating&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">4</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;rating&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Clean word so it matches root word in cleaned reviews</span>
</span></span><span class="line"><span class="cl">    <span class="n">filter_word</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span> <span class="n">clean_text</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>  <span class="o">+</span> <span class="s1">&#39; &#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">#Filter using clean word</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;clean_review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="n">filter_word</span><span class="p">,</span> <span class="n">regex</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Retrieve review distance to center of kmeans cluster</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;distance_to_center&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans_distance</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">vect</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;There are&#34;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">),</span> <span class="n">rating</span><span class="p">,</span> <span class="s2">&#34;reviews that mention:&#34;</span><span class="p">,</span> <span class="n">word</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">asc</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;The most typical reviews are:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;The most atypical reviews are:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="s1">&#39;distance_to_center&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="n">asc</span><span class="p">)[</span><span class="s1">&#39;review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()[:</span><span class="mi">3</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;# &#39;</span><span class="p">,</span> <span class="n">each</span><span class="p">)</span>
</span></span></code></pre></div><h1 id="pseudo-evaluation">Pseudo-evaluation<a hidden class="anchor" aria-hidden="true" href="#pseudo-evaluation">#</a></h1>
<p>We don&rsquo;t really have a way to evaluate this model, so we&rsquo;re going to have to use some intuition! Firstly, let&rsquo;s look at what the 3 most typical positive reviews that mention &ldquo;crocs&rdquo; using TF-IDF and CountVectorizer would say.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;crocs&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 2268 positive reviews that mention: crocs
Most typical reviews are:
#  I love to wear these crocs because they are so comfortable.
#  I love wearing my crocs. They are so comfortable.
#  I love my pair of Crocs. They are so comfortable!
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;crocs&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 2268 positive reviews that mention: crocs
Most typical reviews are:
#  I own a few pairs of crocs and love them all.
#  I love my Crocs; they are so comfortable.
#  I love Crocs; they are so comfortable!
</code></pre>
<p>To make sure we&rsquo;re on the right track, what do the most <em>atypical</em> positive reviews for crocs say? We can find the samples that are farthest from the center by sorting their distance greatest to smallest.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;crocs&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">asc</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 2268 positive reviews that mention: crocs
Most atypical reviews are:
#  Lids adore their Crocs! Fun with swapping charms and accessoryizing.
#  Purr Nickis Impact Crocs. Ima need you to give my girl a ha check!!!!
#  You can turn any none-croc person into a croc lover.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;crocs&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">,</span> <span class="n">asc</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 2268 positive reviews that mention: crocs
Most atypical reviews are:
#  Do you really need one more Croc review to convince you to buy these shoes? Never in a kabillion years did I think I'd ever buy a pair of Crocs. Nope, not my style, not my vibe, and not me, ever. But the husband had plantar fasciitis in one of his feet, and the pain was incredible. There are several options for shoes, but we're on a budget, and I kept reading about Crocs as a good starting point. So I ordered him some Crocs in the olive green. Then I thought, &quot;My husband is a big baby. I should order myself a pair, wear them around for a day, and rave about them so he'll immediately start wearing his own pair of Crocs and start healing his feet.&quot; The thing is, I was totally gobsmacked. At first the prickly nubs in the footbed were a bit distracting, but as I started walking around in them, they became less noticeable, and within the first twenty minutes or so, my feet started to feel energized and soothed. I went outside and swept the deck and did some chicken chores, and I was just in heaven. My legs felt supported and I had this incredible feeling of a whole body support system, starting with the acupressure from the footbed nubs and the lightweight shoe material and the fabulous cushioning. These shoes haven't had enough time to mold to my feet, and I'm already blissed out wearing them. I got mine in the olive green, too. They're earthy and surprisingly cute. My husband hasn't worn a clog in his entire life and walked off wearing them for the first time as if little elves were sitting inside his shoes and if he stepped down too hard, they'd get squished and died. A few minutes later, I saw him disappear down the hill at the back of our property. He can't walk when he gets home, his feet are in that much pain.
#  I was looking for something to wear at night while I was on the AIDS/Lifecycle. It's a 545 mile bicycle ride from San Francisco to Los Angeles where we raise money for services to HIV+ patients. The ride involves six nights of camping. It's a huge event and the evenings involve a lot of walking. We are allowed 70lbs of gear, but we have to haul our gear to our tent site every night, so traveling light is important. I wanted one pair of shoes for the week that I could put on after riding my bike all day and they would be comfortable enough to wear all week. I wanted one pair of shoes that wasn't going to get icky if the grass was wet at the campsite in the morning. I wanted one pair of shoes that kept my feet warm while I was walking around the campsite in the evening. These shoes totally fit the bill. After beating up my feet all day in cleats on the bike, they were a welcome respite. They allowed air to flow, but my feet never got cold at night. Dirt just wiped off. If I got some gravel in them, it kicked right back out. These shoes were so comfortable I found myself next to the gear trucks digging through my bag to find them and put them on. I know a lot of athletes use Crocs after their activity to kick around in, and these shoes are the shiznit!
#  These are my first Crocs, and lavender seems to run *almost* a size small. I would say the size 8 Crocs in lavender fits closer to 7 than size 8 street shoes. For reference, I wear size 7 in street shoes (Vans, Converse, Franco Sarto boots, Timberland Kinsley boots), size 38 European shoes (Veja), size 8 running shoes (Mizuno Wave Riders), size 8 Vasque Mesa Trek hiking boots. If you can, try them on. When I measured my feet and checked the Crocs size chart, it said I was a size 10, which would have been way too big. Size 8 lavender fit me roomy but comfortable, whether I'm barefoot or wearing thick, fluffy socks, with or without the Crocs shoe strap. They're super comfy!
</code></pre>
<p>Those are definitely a bit weird! But, it looks like we&rsquo;ve built something that works. Very cool.</p>
<h2 id="looking-at-more-keywords-and-ratings">Looking at More Keywords and Ratings<a hidden class="anchor" aria-hidden="true" href="#looking-at-more-keywords-and-ratings">#</a></h2>
<p>Let&rsquo;s see what people have to say about the comfort and fit of crocs that is positive using both our vectorization methods.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;comfort&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 1847 positive reviews that mention: comfort
Most typical reviews are:
#  The crocs are very comfortable. I love them.
#  The crocs are comfortable, and I love them.
#  I love the color and comfort of these crocs!
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;comfort&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 1847 positive reviews that mention: comfort
Most typical reviews are:
#  The crocs are very comfortable. I love them.
#  The crocs are comfortable, and I love them.
#  I love them; they are so comfortable to wear.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 834 positive reviews that mention: fit
Most typical reviews are:
#  Love the color and fit just as comfortably as my other crocs.
#  I love these. They are a perfect fit and very comfortable. I love the color as well.
#  Very comfortable and great fit. I love them.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">,</span> <span class="s1">&#39;positive&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 834 positive reviews that mention: fit
Most typical reviews are:
#  I love them, and they fit great.
#  They are a great fit and are comfortable.
#  These are so comfortable, and it fits perfect!
</code></pre>
<p>What do they say about those aspects that is negative?</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;comfort&#39;</span><span class="p">,</span> <span class="s1">&#39;negative&#39;</span><span class="p">,</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 68 negative reviews that mention: comfort
Most typical reviews are:
#  I loved Crocs until my shoe size went to 8.5. Now the 9 is too big &amp; the 8 is too small. I can't really comfortably wear either pair.
#  I love crocs; they're my favorite. However, for some reason, their sizing has gotten inaccurate. I have an old pair of size 8 women's &amp; it's a perfect comfortable fit, and this time I ordered the same size 8 women's, and it's a little too snug for my comfort, and my toes have less room than usual.
#  I love how comfortable this shoe is. However, I wish they had half sizes because I am a 10 1/2 in women and I knew the regular 10 was going to be small, so I got an 11. I didn't like how big it made my feet look. I hope they change their sizing and add half sizes too.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;comfort&#39;</span><span class="p">,</span> <span class="s1">&#39;negative&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 68 negative reviews that mention: comfort
Most typical reviews are:
#  I like how comfortable they are, but they are not true to size because they are too small.
#  The sole isn't comfortable for my feet. Standing long in the pair can be painful.
#  I bought these for my daughter. She said these are not comfortable like true clogs.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">,</span> <span class="s1">&#39;negative&#39;</span><span class="p">,</span> <span class="s1">&#39;tfidf&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 169 negative reviews that mention: fit
Most typical reviews are:
#  I have over 20 pairs of crocs, and lately, the last 5 pairs I've purchased have all fit differently. I'm usually a men's 8 &amp; recently bought a red pair of the classic clog. They were entirely too big, which made no sense because I have pink ones the same size that fit perfectly. I purchased a purple pair &amp; decided to size down &amp; get a men's 7 &amp; they were way too small (which also made no sense because I have blue crocs the same size that were a more snug fit). My suggestion is to either make half sizes, or stop with this whole &quot;Roomy Fit&quot; thing that you all are doing. There is zero reason why each pair of crocs should have a different fit. I'll never order crocs online again. I highly recommend just going to the store to make your purchase. The return process is also very strenuous because Crocs does not offer exchanges. So now I have to send them back to the store via UPS, wait for my return to be processed, then wait until I can make my way to a crocs store because the closest store in my area is 36.6 miles away. Ridiculous.
#  Well, the crocs do not fit my granddaughter. One is actually a different size than the other. She received another pair of Crocs from her dad, and even though the pair he got her are size 9, and the pair I got her are size 9, the pair he bought her fits and the ones I got her do not. One pair was made in China and one pair was made in Vietnam.
#  I have had several pairs of crocs in the past, different styles and colors. Direct from the company. I have been disappointed in the consistency of the sizing. I had a size 10 in the classic style and wanted another pair in a different color. When they arrived, the fit was at least a size larger and wider than my original pair. Then I exchanged for a size 9. This fit better, but now the left shoe is smaller than the right. Not happy.
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">find_most_typical</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="s1">&#39;fit&#39;</span><span class="p">,</span> <span class="s1">&#39;negative&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>There are 169 negative reviews that mention: fit
Most typical reviews are:
#  I ordered size 11 because they r too big. I thought they fit to size.
#  This pair fits a little short.
#  One pair of my crocs was a perfect fit, but the other fit was weird.
</code></pre>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>Well that was fun! After going through and reading the model outputs, it seems that CountVectorizer works the best for solving this problem. Which makes sense considering we are most concerned with finding the most &ldquo;typical&rdquo; reviews, and CountVectorizer focuses solely on term frequency to represent documents. Using CountVectorizer seems partial to the selection of shorter reviews, which I would consider an advantage in this space. Quick and succinct is the name of the game here. I really like this idea and may deploy a model based on this concept in the future&hellip;</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://chandleru11.github.io/posts/tableau_viz/">
    <span class="title">« Prev</span>
    <br>
    <span>Running Data Dashboard</span>
  </a>
  <a class="next" href="https://chandleru11.github.io/posts/review_scrape/">
    <span class="title">Next »</span>
    <br>
    <span>Building a Product Reviews Webscraper</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://chandleru11.github.io/">Chandler Underwood</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
