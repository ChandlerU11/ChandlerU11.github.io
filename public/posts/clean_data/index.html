<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Cleaning Up Years of Daily Running Data | Chandler Underwood</title>
<meta name="keywords" content="">
<meta name="description" content="In this project I use several techniques to clean up and fill-in my running data from college that spans 6 years.">
<meta name="author" content="Chandler Underwood">
<link rel="canonical" href="https://chandleru11.github.io/posts/clean_data/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css" integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z&#43;V9&#43;cO1A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://chandleru11.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://chandleru11.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://chandleru11.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://chandleru11.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://chandleru11.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://chandleru11.github.io/posts/clean_data/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Cleaning Up Years of Daily Running Data" />
<meta property="og:description" content="In this project I use several techniques to clean up and fill-in my running data from college that spans 6 years." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://chandleru11.github.io/posts/clean_data/" /><meta property="og:image" content="https://chandleru11.github.io/images/papermod-cover.png"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-05-03T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-05-03T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://chandleru11.github.io/images/papermod-cover.png"/>

<meta name="twitter:title" content="Cleaning Up Years of Daily Running Data"/>
<meta name="twitter:description" content="In this project I use several techniques to clean up and fill-in my running data from college that spans 6 years."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://chandleru11.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Cleaning Up Years of Daily Running Data",
      "item": "https://chandleru11.github.io/posts/clean_data/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Cleaning Up Years of Daily Running Data",
  "name": "Cleaning Up Years of Daily Running Data",
  "description": "In this project I use several techniques to clean up and fill-in my running data from college that spans 6 years.",
  "keywords": [
    
  ],
  "articleBody": "\r\u003c!DOCTYPE html\u003e Introduction For those of you that don’t know me personally, I managed to run collegiately for 6 years (thanks Covid?). Over that time I logged a lot of miles and a lot of Garmin activities. I still run quite a bit, but my barn burning days are behind me. I’d like to build a dashboard to get some insights to my running trends during that time as a sort of “last hoorah”, but sadly, a lot of my running data is missing and messy. I think cleaning it up will make for a great project to test my skills! Follow along here as I clean up and fill-in my running data using various techniques such as pulling outside data sources and training some ML models to predict missing values.\nData Read-in and Initial Exploration Below is a first look at my running data from college. Over the span of 6 years, I went for a run at least 1,975 times!\nimport pandas as pd data_path = \"Activities 20\" df = pd.read_csv(data_path + \"17.csv\") for i in range (18,23): df = pd.concat([df, pd.read_csv(data_path + str(i) + \".csv\")]) df = df.reset_index().drop(columns = 'index') df Activity Type Date Favorite Title Distance Calories Time Avg HR Max HR Avg Run Cadence ... Min Temp Surface Interval Decompression Best Lap Time Number of Laps Max Temp Moving Time Elapsed Time Min Elevation Max Elevation 0 Running 2017-12-31 10:48:59 False Sevierville Running 13.62 1,462 01:29:31 0 0 175 ... 0.0 0:00 No 00:00.00 14 0.0 01:29:30 01:32:18 958 1,181 1 Running 2017-12-30 08:44:33 False Sevierville Running 5.83 631 00:41:23 0 0 176 ... 0.0 0:00 No 00:00.00 6 0.0 00:41:25 00:41:35 1,001 1,174 2 Running 2017-12-29 11:21:54 False Sevierville Running 8.22 881 00:50:45 0 0 176 ... 0.0 0:00 No 00:00.00 10 0.0 00:50:45 00:51:27 968 1,167 3 Running 2017-12-29 11:06:10 False Sevierville Running 1.97 209 00:13:42 0 0 174 ... 0.0 0:00 No 00:00.00 2 0.0 00:13:41 00:14:01 1,028 1,178 4 Running 2017-12-28 06:24:02 False Moss Point Running 7.37 797 00:52:04 0 0 173 ... 0.0 0:00 No 00:00.00 8 0.0 00:52:03 00:52:16 64 135 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1970 Running 2022-01-05 08:38:41 False Starkville Running 11.50 1,014 01:19:58 147 163 178 ... 57.2 0:00 No 01:19:57.54 1 75.2 01:19:48 01:22:26 223 402 1971 Running 2022-01-04 10:30:42 False Noxubee County Running 11.01 851 01:07:48 145 169 183 ... 51.8 0:00 No 02:01.19 14 69.8 01:07:39 01:23:25 130 201 1972 Running 2022-01-03 10:29:42 False Starkville Running 15.01 1,349 01:43:07 148 171 179 ... 37.4 0:00 No 01:43:06.81 1 77.0 01:43:04 01:51:40 89 243 1973 Running 2022-01-02 09:07:55 False Leon County Running 8.01 688 00:56:25 141 156 177 ... 77.0 0:00 No 56:24.51 1 86.0 00:56:22 00:58:52 -94 167 1974 Running 2022-01-01 09:45:26 False Tallahassee Running 7.00 593 00:51:11 136 159 175 ... 75.2 0:00 No 51:10.60 1 84.2 00:51:06 00:56:12 -59 205 1975 rows × 38 columns\nLet’s have a look at the columns and datatypes of our dataset.\ndf.info() ",
  "wordCount" : "2743",
  "inLanguage": "en",
  "datePublished": "2024-05-03T00:00:00Z",
  "dateModified": "2024-05-03T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Chandler Underwood"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chandleru11.github.io/posts/clean_data/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Chandler Underwood",
    "logo": {
      "@type": "ImageObject",
      "url": "https://chandleru11.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://chandleru11.github.io/" accesskey="h" title="Chandler Underwood (Alt + H)">Chandler Underwood</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://chandleru11.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://chandleru11.github.io/archives" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://chandleru11.github.io/projects" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="https://chandleru11.github.io/publications" title="Publications">
                    <span>Publications</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://chandleru11.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://chandleru11.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Cleaning Up Years of Daily Running Data
    </h1>
    <div class="post-description">
      In this project I use several techniques to clean up and fill-in my running data from college that spans 6 years.
    </div>
    <div class="post-meta"><span title='2024-05-03 00:00:00 +0000 UTC'>May 3, 2024</span>&nbsp;·&nbsp;13 min&nbsp;·&nbsp;Chandler Underwood

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#data-read-in-and-initial-exploration" aria-label="Data Read-in and Initial Exploration">Data Read-in and Initial Exploration</a></li>
                <li>
                    <a href="#data-cleaning-and-feature-engineering" aria-label="Data Cleaning and Feature Engineering">Data Cleaning and Feature Engineering</a></li>
                <li>
                    <a href="#bringing-in-some-outside-help" aria-label="Bringing in Some Outside Help">Bringing in Some Outside Help</a></li>
                <li>
                    <a href="#fitting-a-model-to-fill-in-our-missing-data" aria-label="Fitting a model to fill-in our missing data">Fitting a model to fill-in our missing data</a></li>
                <li>
                    <a href="#fitting-final-models" aria-label="Fitting final models">Fitting final models</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content">

<!DOCTYPE html>
<html>
<head>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0NTZD30YVX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0NTZD30YVX');
</script>
</head>
</html>

<h2 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>For those of you that don&rsquo;t know me personally, I managed to run collegiately for 6 years (thanks Covid?). Over that time I logged a lot of miles and a lot of Garmin activities. I still run quite a bit, but my barn burning days are behind me. I&rsquo;d like to build a dashboard to get some insights to my running trends during that time as a sort of &ldquo;last hoorah&rdquo;, but sadly, a lot of my running data is missing and messy. I think cleaning it up will make for a great project to test my skills! Follow along here as I clean up and fill-in my running data using various techniques such as pulling outside data sources and training some ML models to predict missing values.</p>
<h2 id="data-read-in-and-initial-exploration">Data Read-in and Initial Exploration<a hidden class="anchor" aria-hidden="true" href="#data-read-in-and-initial-exploration">#</a></h2>
<p>Below is a first look at my running data from college. Over the span of 6 years, I went for a run at least 1,975 times!</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">data_path</span> <span class="o">=</span> <span class="s2">&#34;Activities 20&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="s2">&#34;17.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">23</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">     <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;.csv&#34;</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s1">&#39;index&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span>
</span></span></code></pre></div>

<div  style="overflow-x:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Activity Type</th>
      <th>Date</th>
      <th>Favorite</th>
      <th>Title</th>
      <th>Distance</th>
      <th>Calories</th>
      <th>Time</th>
      <th>Avg HR</th>
      <th>Max HR</th>
      <th>Avg Run Cadence</th>
      <th>...</th>
      <th>Min Temp</th>
      <th>Surface Interval</th>
      <th>Decompression</th>
      <th>Best Lap Time</th>
      <th>Number of Laps</th>
      <th>Max Temp</th>
      <th>Moving Time</th>
      <th>Elapsed Time</th>
      <th>Min Elevation</th>
      <th>Max Elevation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Running</td>
      <td>2017-12-31 10:48:59</td>
      <td>False</td>
      <td>Sevierville Running</td>
      <td>13.62</td>
      <td>1,462</td>
      <td>01:29:31</td>
      <td>0</td>
      <td>0</td>
      <td>175</td>
      <td>...</td>
      <td>0.0</td>
      <td>0:00</td>
      <td>No</td>
      <td>00:00.00</td>
      <td>14</td>
      <td>0.0</td>
      <td>01:29:30</td>
      <td>01:32:18</td>
      <td>958</td>
      <td>1,181</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Running</td>
      <td>2017-12-30 08:44:33</td>
      <td>False</td>
      <td>Sevierville Running</td>
      <td>5.83</td>
      <td>631</td>
      <td>00:41:23</td>
      <td>0</td>
      <td>0</td>
      <td>176</td>
      <td>...</td>
      <td>0.0</td>
      <td>0:00</td>
      <td>No</td>
      <td>00:00.00</td>
      <td>6</td>
      <td>0.0</td>
      <td>00:41:25</td>
      <td>00:41:35</td>
      <td>1,001</td>
      <td>1,174</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Running</td>
      <td>2017-12-29 11:21:54</td>
      <td>False</td>
      <td>Sevierville Running</td>
      <td>8.22</td>
      <td>881</td>
      <td>00:50:45</td>
      <td>0</td>
      <td>0</td>
      <td>176</td>
      <td>...</td>
      <td>0.0</td>
      <td>0:00</td>
      <td>No</td>
      <td>00:00.00</td>
      <td>10</td>
      <td>0.0</td>
      <td>00:50:45</td>
      <td>00:51:27</td>
      <td>968</td>
      <td>1,167</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Running</td>
      <td>2017-12-29 11:06:10</td>
      <td>False</td>
      <td>Sevierville Running</td>
      <td>1.97</td>
      <td>209</td>
      <td>00:13:42</td>
      <td>0</td>
      <td>0</td>
      <td>174</td>
      <td>...</td>
      <td>0.0</td>
      <td>0:00</td>
      <td>No</td>
      <td>00:00.00</td>
      <td>2</td>
      <td>0.0</td>
      <td>00:13:41</td>
      <td>00:14:01</td>
      <td>1,028</td>
      <td>1,178</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Running</td>
      <td>2017-12-28 06:24:02</td>
      <td>False</td>
      <td>Moss Point Running</td>
      <td>7.37</td>
      <td>797</td>
      <td>00:52:04</td>
      <td>0</td>
      <td>0</td>
      <td>173</td>
      <td>...</td>
      <td>0.0</td>
      <td>0:00</td>
      <td>No</td>
      <td>00:00.00</td>
      <td>8</td>
      <td>0.0</td>
      <td>00:52:03</td>
      <td>00:52:16</td>
      <td>64</td>
      <td>135</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1970</th>
      <td>Running</td>
      <td>2022-01-05 08:38:41</td>
      <td>False</td>
      <td>Starkville Running</td>
      <td>11.50</td>
      <td>1,014</td>
      <td>01:19:58</td>
      <td>147</td>
      <td>163</td>
      <td>178</td>
      <td>...</td>
      <td>57.2</td>
      <td>0:00</td>
      <td>No</td>
      <td>01:19:57.54</td>
      <td>1</td>
      <td>75.2</td>
      <td>01:19:48</td>
      <td>01:22:26</td>
      <td>223</td>
      <td>402</td>
    </tr>
    <tr>
      <th>1971</th>
      <td>Running</td>
      <td>2022-01-04 10:30:42</td>
      <td>False</td>
      <td>Noxubee County Running</td>
      <td>11.01</td>
      <td>851</td>
      <td>01:07:48</td>
      <td>145</td>
      <td>169</td>
      <td>183</td>
      <td>...</td>
      <td>51.8</td>
      <td>0:00</td>
      <td>No</td>
      <td>02:01.19</td>
      <td>14</td>
      <td>69.8</td>
      <td>01:07:39</td>
      <td>01:23:25</td>
      <td>130</td>
      <td>201</td>
    </tr>
    <tr>
      <th>1972</th>
      <td>Running</td>
      <td>2022-01-03 10:29:42</td>
      <td>False</td>
      <td>Starkville Running</td>
      <td>15.01</td>
      <td>1,349</td>
      <td>01:43:07</td>
      <td>148</td>
      <td>171</td>
      <td>179</td>
      <td>...</td>
      <td>37.4</td>
      <td>0:00</td>
      <td>No</td>
      <td>01:43:06.81</td>
      <td>1</td>
      <td>77.0</td>
      <td>01:43:04</td>
      <td>01:51:40</td>
      <td>89</td>
      <td>243</td>
    </tr>
    <tr>
      <th>1973</th>
      <td>Running</td>
      <td>2022-01-02 09:07:55</td>
      <td>False</td>
      <td>Leon County Running</td>
      <td>8.01</td>
      <td>688</td>
      <td>00:56:25</td>
      <td>141</td>
      <td>156</td>
      <td>177</td>
      <td>...</td>
      <td>77.0</td>
      <td>0:00</td>
      <td>No</td>
      <td>56:24.51</td>
      <td>1</td>
      <td>86.0</td>
      <td>00:56:22</td>
      <td>00:58:52</td>
      <td>-94</td>
      <td>167</td>
    </tr>
    <tr>
      <th>1974</th>
      <td>Running</td>
      <td>2022-01-01 09:45:26</td>
      <td>False</td>
      <td>Tallahassee Running</td>
      <td>7.00</td>
      <td>593</td>
      <td>00:51:11</td>
      <td>136</td>
      <td>159</td>
      <td>175</td>
      <td>...</td>
      <td>75.2</td>
      <td>0:00</td>
      <td>No</td>
      <td>51:10.60</td>
      <td>1</td>
      <td>84.2</td>
      <td>00:51:06</td>
      <td>00:56:12</td>
      <td>-59</td>
      <td>205</td>
    </tr>
  </tbody>
</table>
<p>1975 rows × 38 columns</p>
</div>

<p>Let&rsquo;s have a look at the columns and datatypes of our dataset.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1975 entries, 0 to 1974
Data columns (total 38 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   Activity Type             1975 non-null   object 
 1   Date                      1975 non-null   object 
 2   Favorite                  1975 non-null   bool   
 3   Title                     1975 non-null   object 
 4   Distance                  1975 non-null   float64
 5   Calories                  1975 non-null   object 
 6   Time                      1975 non-null   object 
 7   Avg HR                    1975 non-null   int64  
 8   Max HR                    1975 non-null   int64  
 9   Avg Run Cadence           1975 non-null   object 
 10  Max Run Cadence           1975 non-null   object 
 11  Avg Pace                  1975 non-null   object 
 12  Best Pace                 1975 non-null   object 
 13  Total Ascent              1975 non-null   object 
 14  Total Descent             1975 non-null   object 
 15  Avg Stride Length         1975 non-null   float64
 16  Avg Vertical Ratio        1975 non-null   float64
 17  Avg Vertical Oscillation  1975 non-null   float64
 18  Avg Ground Contact Time   1975 non-null   int64  
 19  Training Stress Score®    1975 non-null   float64
 20  Avg Power                 1975 non-null   int64  
 21  Max Power                 1975 non-null   int64  
 22  Grit                      1975 non-null   float64
 23  Flow                      1975 non-null   float64
 24  Avg. Swolf                1975 non-null   int64  
 25  Avg Stroke Rate           1975 non-null   int64  
 26  Total Reps                1975 non-null   int64  
 27  Dive Time                 1975 non-null   object 
 28  Min Temp                  1975 non-null   float64
 29  Surface Interval          1975 non-null   object 
 30  Decompression             1975 non-null   object 
 31  Best Lap Time             1975 non-null   object 
 32  Number of Laps            1975 non-null   object 
 33  Max Temp                  1975 non-null   float64
 34  Moving Time               1975 non-null   object 
 35  Elapsed Time              1975 non-null   object 
 36  Min Elevation             1975 non-null   object 
 37  Max Elevation             1975 non-null   object 
dtypes: bool(1), float64(9), int64(8), object(20)
memory usage: 573.0+ KB
</code></pre>
<p>As you may have guessed, after reading Garmin&rsquo;s documentation, many of the data&rsquo;s attributes are not useful to us as they are not metrics taken for runs such as <em>Max Power</em> (a cycling metric) and <em>Avg Stroke Rate</em> (a swimming metric). In the cleanup and feature engineering section, we&rsquo;ll drop those and many others that aren&rsquo;t helpful for understanding my running performances.</p>
<p>The first issue with this dataset is that the <em>Avg HR</em> and <em>Max HR</em> columns are populated with some zeros (see table above), and I assure you that my heart was beating faster than that! The <em>Max Temp</em> and <em>Min Temp</em> columns also contain some zeroes. This is because I didn&rsquo;t have a fancy watch in the beginning of college that logged those metrics. Because of this we can assume that the 0&rsquo;s populating those four columns are actually NULL / missing values. Many of our columns should contain numerical data but instead contain strings such as <em>Min Elevation</em>, so we are going to fix that in the next section too.</p>
<h2 id="data-cleaning-and-feature-engineering">Data Cleaning and Feature Engineering<a hidden class="anchor" aria-hidden="true" href="#data-cleaning-and-feature-engineering">#</a></h2>
<p>First thing we need to do is drop those extraneous columns and correct the data types for our remaining columns.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Drop extraneous columns</span>
</span></span><span class="line"><span class="cl"><span class="n">cols_to_keep</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="s1">&#39;Title&#39;</span><span class="p">,</span> <span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg Pace&#39;</span><span class="p">,</span> <span class="s1">&#39;Best Pace&#39;</span><span class="p">,</span> <span class="s1">&#39;Distance&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Calories&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg HR&#39;</span><span class="p">,</span> <span class="s1">&#39;Max HR&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg Run Cadence&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Max Run Cadence&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Ascent&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Total Descent&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg Stride Length&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Elevation&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Max Elevation&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cols_to_keep</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Replace missing values with NaN for easy pandas manipulation</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>  <span class="c1">#String Garmin uses in place of NaN</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Remove commas so we can convert these columns to numerical data</span>
</span></span><span class="line"><span class="cl"><span class="n">cols_to_clean</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Calories&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Ascent&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Descent&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Elevation&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Elevation&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="n">cols_to_clean</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cols_to_clean</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span><span class="s1">&#39;,&#39;</span><span class="p">:</span><span class="s1">&#39;&#39;</span><span class="p">},</span> <span class="n">regex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Conversion of columns to floats for use in models</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">float_convert</span><span class="p">(</span><span class="n">col</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">float_convert</span><span class="p">(</span><span class="n">cols_to_keep</span><span class="p">[</span><span class="mi">5</span><span class="p">:])</span>
</span></span></code></pre></div><p>There are a few important columns that are written in a time format that is useful for humans but not machines. Let&rsquo;s engineer some new features using them.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">#Drop activities saved by accident</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Avg Pace&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Best Pace&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Convert values to float representing an equal amount of time in minutes</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Total Run Time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mi">60</span> <span class="o">*</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">/</span><span class="mi">60</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Time&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Avg Pace&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">60</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Avg Pace&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Best Pace&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="mi">60</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Best Pace&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#My college running days ended on the date below</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="s2">&#34;2022-05-15&#34;</span><span class="p">)]</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 1883 entries, 0 to 1974
Data columns (total 18 columns):
 #   Column             Non-Null Count  Dtype         
---  ------             --------------  -----         
 0   Date               1883 non-null   datetime64[ns]
 1   Title              1883 non-null   object        
 2   Avg Pace           1883 non-null   float64       
 3   Best Pace          1883 non-null   float64       
 4   Distance           1883 non-null   float64       
 5   Calories           1883 non-null   float64       
 6   Avg HR             607 non-null    float64       
 7   Max HR             607 non-null    float64       
 8   Avg Run Cadence    1883 non-null   float64       
 9   Max Run Cadence    1883 non-null   float64       
 10  Total Ascent       1855 non-null   float64       
 11  Total Descent      1861 non-null   float64       
 12  Avg Stride Length  1883 non-null   float64       
 13  Min Temp           607 non-null    float64       
 14  Max Temp           607 non-null    float64       
 15  Min Elevation      1875 non-null   float64       
 16  Max Elevation      1880 non-null   float64       
 17  Total Run Time     1883 non-null   float64       
dtypes: datetime64[ns](1), float64(16), object(1)
memory usage: 279.5+ KB
</code></pre>
<p>Over half of the values in the <em>Avg HR</em>, <em>Max HR</em>, <em>Min Temp</em> and <em>Max Temp</em> columns are NULL. Remember, I&rsquo;m doing this, so I can get a better understanding of trends in my running data over the years I ran in college. I want to create some visualizations with this data in the future, and all these values are important in getting a &ldquo;big picture&rdquo; look at my running trends. To deal with the missing data, we have four options:</p>
<ol>
<li>Drop the rows that are missing data.</li>
<li>Fill NULL rows with some sort of common value (oftentimes the median of the column in question).</li>
<li>Bring in an outside data source.</li>
<li>Create a predictive model.</li>
</ol>
<p>Option 1 is not going to work here as that would eliminate nearly two thirds of my data. Option 2 works OK for the columns that are missing only a few features, but it would definitely take away from the richness of the data and make for some boring / unhelpful visualizations if we used it for all the missing values in the dataset. But, option 3 can work great for filling in the temperature data as it is easy to find weather data, and option 4 is the way to go for fixing the HR data.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">#Using Option 2 to infill missing data with only a few NULLs</span>
</span></span><span class="line"><span class="cl"><span class="n">cols_with_few_nan</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Total Ascent&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Descent&#39;</span><span class="p">,</span><span class="s1">&#39;Min Elevation&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Elevation&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="n">cols_with_few_nan</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cols_with_few_nan</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">cols_with_few_nan</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span>
</span></span></code></pre></div><h2 id="bringing-in-some-outside-help">Bringing in Some Outside Help<a hidden class="anchor" aria-hidden="true" href="#bringing-in-some-outside-help">#</a></h2>
<p>Unfortunately, Garmin uses a somewhat cryptic system to log the location of runs. It usually titles each activity as either the county or city name plus &ldquo;Running&rdquo; with no other geolocation data to go along with it. To help us get started, let&rsquo;s look at where my runs occurred that are missing temperature data.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">run_locations</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Min Temp&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isna</span><span class="p">()][</span><span class="s1">&#39;Title&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">sorted</span><span class="p">(</span><span class="n">run_locations</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span>
</span></span></code></pre></div><pre><code>[('Oktibbeha County Running', 349),
 ('Starkville Running', 245),
 ('Flowood Running', 127),
 ('Jackson County Running', 120),
 ('Moss Point Running', 64),
 ('Mobile County Running', 50),
 ('Boulder County Running', 43),
 ('Lucedale Running', 31),
 ('Oktibbeha County - Running', 21),
 ('Boulder Running', 21)]
</code></pre>
<p>Despite differing titles, the vast majority of these samples occur either in my old college town of Starkville, MS or very close to it, and nearly all the rest occur somewhere in Mississippi or in the South. Because we don&rsquo;t have a way to convert these titles to a more specific location without getting really messy, I believe it will suffice to use weather data for Starkville, MS as a proxy for all the missing values we have.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df_weather</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&#34;Weather Data.csv&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df_weather</span> <span class="o">=</span> <span class="n">df_weather</span><span class="p">[[</span><span class="s1">&#39;NAME&#39;</span><span class="p">,</span><span class="s1">&#39;DATE&#39;</span><span class="p">,</span><span class="s1">&#39;TMAX&#39;</span><span class="p">,</span><span class="s1">&#39;TMIN&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">df_weather</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s1">&#39;index&#39;</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df_weather</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df_weather</span><span class="p">[</span><span class="s1">&#39;DATE&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">df_weather</span><span class="p">[</span><span class="s1">&#39;Min Temp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_weather</span><span class="p">[</span><span class="s1">&#39;TMIN&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">df_weather</span><span class="p">[</span><span class="s1">&#39;Max Temp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_weather</span><span class="p">[</span><span class="s1">&#39;TMAX&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Dataset contains weather reports from several locations surrounding Starkville, so we can group them together. </span>
</span></span><span class="line"><span class="cl"><span class="n">df_weather</span> <span class="o">=</span> <span class="n">df_weather</span><span class="p">[[</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Temp&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">by</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Perform inner join, giving us a 1:1 ratio of dates to temperatures</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Min Temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Temp&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df_weather</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s1">&#39;inner&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Infill any remaining missing temperature values with the median</span>
</span></span><span class="line"><span class="cl"><span class="n">cols_with_few_nan</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Min Temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Temp&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="n">cols_with_few_nan</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">cols_with_few_nan</span><span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">cols_with_few_nan</span><span class="p">]</span><span class="o">.</span><span class="n">median</span><span class="p">())</span>
</span></span></code></pre></div><p>There you have it, our filled in temperature data. Now, we need to build a model(s) that can effectively populate the missing values in our Max HR and Avg HR columns.</p>
<h2 id="fitting-a-model-to-fill-in-our-missing-data">Fitting a model to fill-in our missing data<a hidden class="anchor" aria-hidden="true" href="#fitting-a-model-to-fill-in-our-missing-data">#</a></h2>
<p>Let&rsquo;s train and evaluate some regression models to fill in all that missing heart rate data. In the end we will have built two models, one to predict the <em>Avg HR</em> columns and another to predict <em>Max HR</em>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1">#Select subset of data with no missing values for training</span>
</span></span><span class="line"><span class="cl"><span class="n">df_train</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Training features</span>
</span></span><span class="line"><span class="cl"><span class="n">X_train</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[[</span><span class="s1">&#39;Avg Pace&#39;</span><span class="p">,</span> <span class="s1">&#39;Best Pace&#39;</span><span class="p">,</span> <span class="s1">&#39;Distance&#39;</span><span class="p">,</span> <span class="s1">&#39;Calories&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Avg Run Cadence&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Run Cadence&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Total Ascent&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Descent&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg Stride Length&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Elevation&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Max Elevation&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Run Time&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Temp&#39;</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y_avg</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;Avg HR&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">y_max</span> <span class="o">=</span> <span class="n">df_train</span><span class="p">[</span><span class="s1">&#39;Max HR&#39;</span><span class="p">]</span>
</span></span></code></pre></div><p>Because of my running domain knowledge, I have an idea of what features will be useful for predicting the <em>Max HR</em> and <em>Avg HR</em> columns of our data, but I&rsquo;m a fan of letting scikit-learn decide what features are best for me. Let&rsquo;s select the best 5 features.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_regression</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#The best features to predict Avg HR are not necessarily the best to predict Max HR</span>
</span></span><span class="line"><span class="cl"><span class="n">kb_average</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_regression</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_avg</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">kb_max</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_regression</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">X_avg</span> <span class="o">=</span> <span class="n">kb_average</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">X_max</span> <span class="o">=</span> <span class="n">kb_max</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</span></span></code></pre></div><p>Now we can use those extracted features to train several regression models and evaluate using cross validation to pick the best one for our two prediction tasks. The evaluation metrics we&rsquo;ll use are Mean Absolute Error (MAE) and Mean Squared Error (MSE).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Lasso</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVR</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">mean_squared_error</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">statistics</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">cv</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">score</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;neg_mean_absolute_error&#39;</span><span class="p">,</span> <span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Model: &#34;</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Test Mean Absolute Error: &#34;</span><span class="p">,</span> <span class="n">statistics</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">score</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_absolute_error&#39;</span><span class="p">]),</span> 
</span></span><span class="line"><span class="cl">          <span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Test Mean Squared Error: &#34;</span><span class="p">,</span> <span class="n">statistics</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">score</span><span class="p">[</span><span class="s1">&#39;test_neg_mean_squared_error&#39;</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">regr</span> <span class="o">=</span> <span class="n">SVR</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rfr</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">data_list</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_avg</span><span class="p">,</span> <span class="n">y_avg</span><span class="p">,</span> <span class="s2">&#34;HR Avg&#34;</span><span class="p">),</span> <span class="p">(</span><span class="n">X_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="s2">&#34;HR Max&#34;</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl"><span class="n">model_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;Lasso Regression&#34;</span><span class="p">:</span><span class="n">lasso</span><span class="p">,</span> <span class="s2">&#34;Linear Regression&#34;</span><span class="p">:</span><span class="n">reg</span><span class="p">,</span> <span class="s2">&#34;SVR&#34;</span><span class="p">:</span><span class="n">regr</span><span class="p">,</span> <span class="s2">&#34;RF Regressor&#34;</span><span class="p">:</span><span class="n">rfr</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_list</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">############################</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">model_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="n">cv</span><span class="p">(</span><span class="n">model_dict</span><span class="p">[</span><span class="n">model</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">model</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>############################
 HR Avg

Model:  Lasso Regression
Test Mean Absolute Error:  -3.4721680220384203 
Test Mean Squared Error:  -21.528693269323934

Model:  Linear Regression
Test Mean Absolute Error:  -3.4965374931940674 
Test Mean Squared Error:  -21.794449648893643

Model:  SVR
Test Mean Absolute Error:  -6.503686070502235 
Test Mean Squared Error:  -64.17778768337854

Model:  RF Regressor
Test Mean Absolute Error:  -3.6666079473371216 
Test Mean Squared Error:  -22.542642038967205

############################
 HR Max

Model:  Lasso Regression
Test Mean Absolute Error:  -6.310069863144789 
Test Mean Squared Error:  -67.01035553775584

Model:  Linear Regression
Test Mean Absolute Error:  -6.332889188711009 
Test Mean Squared Error:  -67.28914455377931

Model:  SVR
Test Mean Absolute Error:  -7.571264852476413 
Test Mean Squared Error:  -91.18257365781352

Model:  RF Regressor
Test Mean Absolute Error:  -5.748229756457544 
Test Mean Squared Error:  -57.09265923926437
</code></pre>
<p>Lasso regression is the best model for predicting the Average Heart Rate of my runs while Random Forest Regressor is the best at predicting the Max Heart Rate.</p>
<h2 id="fitting-final-models">Fitting final models<a hidden class="anchor" aria-hidden="true" href="#fitting-final-models">#</a></h2>
<p>Let&rsquo;s fit the best performing models using their entire respective training sets and predict on the samples that are missing HR data.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">lasso_avg</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">lasso_avg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_avg</span><span class="p">,</span> <span class="n">y_avg</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">rfr_max</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rfr_max</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Select predictive features from entire dataset</span>
</span></span><span class="line"><span class="cl"><span class="n">X_full</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Avg Pace&#39;</span><span class="p">,</span> <span class="s1">&#39;Best Pace&#39;</span><span class="p">,</span> <span class="s1">&#39;Distance&#39;</span><span class="p">,</span> <span class="s1">&#39;Calories&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Avg Run Cadence&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Run Cadence&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Total Ascent&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Descent&#39;</span><span class="p">,</span> <span class="s1">&#39;Avg Stride Length&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Elevation&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">       <span class="s1">&#39;Max Elevation&#39;</span><span class="p">,</span> <span class="s1">&#39;Total Run Time&#39;</span><span class="p">,</span> <span class="s1">&#39;Min Temp&#39;</span><span class="p">,</span> <span class="s1">&#39;Max Temp&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Predict for all samples and infill rows that are missing values</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Max HR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Max HR&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">combine_first</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">rfr_max</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">kb_max</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_full</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Avg HR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Avg HR&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">combine_first</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">lasso_avg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">kb_average</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_full</span><span class="p">))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Running_Data_Clean.csv&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span>
</span></span></code></pre></div>

<div  style="overflow-x:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Title</th>
      <th>Avg Pace</th>
      <th>Best Pace</th>
      <th>Distance</th>
      <th>Calories</th>
      <th>Avg HR</th>
      <th>Max HR</th>
      <th>Avg Run Cadence</th>
      <th>Max Run Cadence</th>
      <th>Total Ascent</th>
      <th>Total Descent</th>
      <th>Avg Stride Length</th>
      <th>Min Elevation</th>
      <th>Max Elevation</th>
      <th>Total Run Time</th>
      <th>Min Temp</th>
      <th>Max Temp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2017-12-31</td>
      <td>Sevierville Running</td>
      <td>6.566667</td>
      <td>5.983333</td>
      <td>13.62</td>
      <td>1462.0</td>
      <td>179.348833</td>
      <td>175.218101</td>
      <td>175.0</td>
      <td>187.0</td>
      <td>381.0</td>
      <td>425.0</td>
      <td>1.40</td>
      <td>958.0</td>
      <td>1181.0</td>
      <td>89.516667</td>
      <td>22.0</td>
      <td>46.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2017-12-30</td>
      <td>Sevierville Running</td>
      <td>7.100000</td>
      <td>6.533333</td>
      <td>5.83</td>
      <td>631.0</td>
      <td>151.453714</td>
      <td>168.844806</td>
      <td>176.0</td>
      <td>191.0</td>
      <td>169.0</td>
      <td>9.0</td>
      <td>1.29</td>
      <td>1001.0</td>
      <td>1174.0</td>
      <td>41.383333</td>
      <td>27.0</td>
      <td>49.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2017-12-29</td>
      <td>Sevierville Running</td>
      <td>6.166667</td>
      <td>5.350000</td>
      <td>8.22</td>
      <td>881.0</td>
      <td>163.870123</td>
      <td>176.137507</td>
      <td>176.0</td>
      <td>191.0</td>
      <td>285.0</td>
      <td>184.0</td>
      <td>1.47</td>
      <td>968.0</td>
      <td>1167.0</td>
      <td>50.750000</td>
      <td>28.0</td>
      <td>44.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2017-12-29</td>
      <td>Sevierville Running</td>
      <td>6.950000</td>
      <td>6.316667</td>
      <td>1.97</td>
      <td>209.0</td>
      <td>139.974450</td>
      <td>164.446402</td>
      <td>174.0</td>
      <td>191.0</td>
      <td>48.0</td>
      <td>181.0</td>
      <td>1.34</td>
      <td>1028.0</td>
      <td>1178.0</td>
      <td>13.700000</td>
      <td>28.0</td>
      <td>44.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2017-12-28</td>
      <td>Moss Point Running</td>
      <td>7.066667</td>
      <td>6.383333</td>
      <td>7.37</td>
      <td>797.0</td>
      <td>156.137539</td>
      <td>171.490540</td>
      <td>173.0</td>
      <td>185.0</td>
      <td>182.0</td>
      <td>195.0</td>
      <td>1.32</td>
      <td>64.0</td>
      <td>135.0</td>
      <td>52.066667</td>
      <td>25.0</td>
      <td>42.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1878</th>
      <td>2022-01-05</td>
      <td>Starkville Running</td>
      <td>6.950000</td>
      <td>6.316667</td>
      <td>11.50</td>
      <td>1014.0</td>
      <td>147.000000</td>
      <td>163.000000</td>
      <td>178.0</td>
      <td>201.0</td>
      <td>420.0</td>
      <td>404.0</td>
      <td>1.30</td>
      <td>223.0</td>
      <td>402.0</td>
      <td>79.966667</td>
      <td>33.0</td>
      <td>55.0</td>
    </tr>
    <tr>
      <th>1879</th>
      <td>2022-01-04</td>
      <td>Noxubee County Running</td>
      <td>6.166667</td>
      <td>4.483333</td>
      <td>11.01</td>
      <td>851.0</td>
      <td>145.000000</td>
      <td>169.000000</td>
      <td>183.0</td>
      <td>232.0</td>
      <td>289.0</td>
      <td>246.0</td>
      <td>1.42</td>
      <td>130.0</td>
      <td>201.0</td>
      <td>67.800000</td>
      <td>30.0</td>
      <td>40.5</td>
    </tr>
    <tr>
      <th>1880</th>
      <td>2022-01-03</td>
      <td>Starkville Running</td>
      <td>6.866667</td>
      <td>5.650000</td>
      <td>15.01</td>
      <td>1349.0</td>
      <td>148.000000</td>
      <td>171.000000</td>
      <td>179.0</td>
      <td>190.0</td>
      <td>807.0</td>
      <td>774.0</td>
      <td>1.31</td>
      <td>89.0</td>
      <td>243.0</td>
      <td>103.116667</td>
      <td>29.5</td>
      <td>51.0</td>
    </tr>
    <tr>
      <th>1881</th>
      <td>2022-01-02</td>
      <td>Leon County Running</td>
      <td>7.050000</td>
      <td>5.716667</td>
      <td>8.01</td>
      <td>688.0</td>
      <td>141.000000</td>
      <td>156.000000</td>
      <td>177.0</td>
      <td>188.0</td>
      <td>810.0</td>
      <td>978.0</td>
      <td>1.29</td>
      <td>-94.0</td>
      <td>167.0</td>
      <td>56.416667</td>
      <td>30.0</td>
      <td>65.0</td>
    </tr>
    <tr>
      <th>1882</th>
      <td>2022-01-01</td>
      <td>Tallahassee Running</td>
      <td>7.316667</td>
      <td>5.300000</td>
      <td>7.00</td>
      <td>593.0</td>
      <td>136.000000</td>
      <td>159.000000</td>
      <td>175.0</td>
      <td>186.0</td>
      <td>801.0</td>
      <td>863.0</td>
      <td>1.26</td>
      <td>-59.0</td>
      <td>205.0</td>
      <td>51.183333</td>
      <td>61.5</td>
      <td>79.0</td>
    </tr>
  </tbody>
</table>
<p>1883 rows × 18 columns</p>
</div>


<p>There you have it, a NULL-free, clean dataset. We are dashboard ready now. Check out my next post to see what I can make with this in Tableau.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
<nav class="paginav">
  <a class="prev" href="https://chandleru11.github.io/posts/review_scrape/">
    <span class="title">« Prev</span>
    <br>
    <span>Building a Product Reviews Webscraper</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://chandleru11.github.io/">Chandler Underwood</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
